{
 "metadata": {
  "name": "",
  "signature": "sha256:f99a462cc537092ba3ba3cfcfdd4f81d02dc9b832a31d91106906a7d73c3ad28"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Meta-d' calculation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%install_ext https://raw.githubusercontent.com/rasbt/python_reference/master/ipython_magic/watermark.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Installed watermark.py. To use it, type:\n",
        "  %load_ext watermark\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Just run once!!!\n",
      "%load_ext watermark"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%watermark -d -a \"Atesh Koul\" "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Atesh Koul 23/01/2015 \n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "20/01/2015:\n",
      "\n",
      "Important points (from papers) :\n",
      "\n",
      "<cite data-cite=\"McCurdy2013\">(Li Yan McCurdy, 2013)</cite>:\n",
      "\n",
      "Thus, although we cannot experimentally control for variability in basic task performance, this is easily corrected by normalizing meta-d\u2032 by d\u2032. \n",
      "\n",
      "\n",
      "<cite data-cite=\"Massoni2014\">(Massoni, 2014)</cite> :\n",
      "\n",
      "Calibration is obtained by computing the mean of the difference between confidence and accuracy. Discrimination is measured by the difference between meta-d0 and d0. TheCalibration is obtained by computing the mean of the difference between confidence and accuracy. Discrimination is measured by the difference between meta-d0 and d0.\n",
      "\n",
      "\n",
      "Ko2012\n",
      "\n",
      "http://scholar.google.it/scholar?q=%22http%3A%2F%2Fwww.columbia.edu%2F~bsm2105%2Ftype2sdt%2F%22&btnG=&hl=en&as_sdt=0%2C5"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It seems that what is S1 and S2 is according to their paper, which stimulus \u2013 left or right side stimulus. The stimulus seems to be the same. But they call it S1 and S2 based on if it is on the left or the right of the screen. For us, it will be first interval or the second interval i.e. the where the signal is. This is the same column as in the position signal in the results.  \u201d After stimulus presentation, subjects provided a forced-choice judgment of whether the left or the right stimulus contained a grating.\u201d\n",
      "\n",
      "\n",
      "Couple of things that are also essential are to check that the \n",
      "* Response is not the accuracy \u2013 accuracy depends on the position of the signal and the response button pressed. But in the original script, response is required not accuracy. \n",
      "* We have two blocks where the object changes. However, the position of the signal is accordingly changed in the results. So, there is no need to separately analyze the two blocks. (alternatively, we can just calculate it to check).\n",
      "* Null values are treated differently in matlab and in excel. If u copy paste values, null values change to 0. Which is terrible. That changes a lot of things. (P.S. 0 values in case of confidence rating are ok but not in response \u2013 where no response has been provided.)\n",
      "* In some (rare) cases, there are instead of \u2018l\u2019 or \u2018a\u2019 response, a response of 4$ or 3#, This gets converted to 0 using the excel formula/macro. Very critical to check!!!\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Updates:\n",
      "\n",
      "There are a lot of things that I have been trying out:\n",
      "Some of the things could be that there might be difference in the block 1 vs block 2. Although, this should not be the case. The reason I say this is because the signal is automatically changed according to the block. The only doubt that I have is with respect to the button response. \n",
      "\n",
      "In the first case, the signal means S1 is the first interval stimulus and S2 is the 2nd interval stimuls. \n",
      "\n",
      "Seems like what I was doing was correct and there is no need to reverse the responses for block two. This is because what i got from the type 1 d' from the algorithm using my approach (not changing the response) is closer to the one that was independently obtained from the analysis by lab ppl (Andrea or Caterina). However, when i change the response, the d' is completely different.\n",
      "\n",
      "\n",
      "What I need to check is the units in which the meta-d' is outputted. This should be the same as in d' as the value of d' from algorithm matches the independent one.\n",
      "\n",
      "Need to check for more participants.\n",
      "\n",
      "I will also check using the SLE approach.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%watermark -d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "23/01/2015 \n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are a lot of other updates with the SSE.. Just like trails to count accompanying file is there. there is another file - type2_SDT_SSE.m that helps calculate the type 1 parameters and is useful for fit_meta_d_SSE.m file. I would calculate the parameters from it and try n compare with the ones for MLE method.\n",
      "\n",
      "Some issues with data from Lateral participant 2 as it seems to be already \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%watermark -d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "26/01/2015 \n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So I also checked the other stuff like the interpretation given in the examples. From the file trials2count.m :\n",
      "% e.g. if nR_S1 = [100 50 20 10 5 1], then when stimulus S1 was\n",
      "% presented, the subject had the following response counts:\n",
      "% responded S1, rating=3 : 100 times\n",
      "% responded S1, rating=2 : 50 times\n",
      "% responded S1, rating=1 : 20 times\n",
      "% responded S2, rating=1 : 10 times\n",
      "% responded S2, rating=2 : 5 times\n",
      "% responded S2, rating=3 : 1 time\n",
      "\n",
      "\n",
      "When I check this with Subject 2 Lateral data, for time bin 1st, I get nR_S1 = [0     0     0    10     7     0     0     0] and nR_S2 = [0     0     0     6     7     0     0     0]. The data had all ones -\n",
      "    [1     1     1\n",
      "     1     1     0\n",
      "     1     0     0\n",
      "     1     1     0\n",
      "     1     0     0\n",
      "     1     0     1\n",
      "     1     1     1\n",
      "     1     1     0\n",
      "     1     0     1\n",
      "     1     1     0\n",
      "     1     0     0\n",
      "     1     1     0\n",
      "     1     1     1\n",
      "     1     0     0\n",
      "     1     1     0\n",
      "     1     1     1\n",
      "     1     0     0\n",
      "     1     0     0\n",
      "     1     1     1\n",
      "     1     0     1\n",
      "     1     1     1\n",
      "     1     0     0\n",
      "     1     1     1\n",
      "     1     0     0\n",
      "     1     0     1\n",
      "     1     0     0\n",
      "     1     0     0\n",
      "     1     0     1\n",
      "     1     1     0\n",
      "     1     0     1]\n",
      "     \n",
      "     \n",
      "With column 1 = conf rating, col 2 = response given (1 = 'a', 0 = 'l' which for us is S1 and S2), col 3 = Posizione Segnale (1 = 'S1, 0 = 'S2'). \n",
      "\n",
      "This corresponds correctly to the interpretation. Here in this case, padding has not been applied which can cause problems with the optimization.\n",
      "\n",
      "\n",
      "The interesting thing (and comforting thing) is that the type 1 d' values are more or less similar to what have been calculated before.\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data Preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Data preprocessing was done in the following way: \n",
      "* The data was copied from the excel file from the columns signal, bin, confidence, Posizione Segnale, Resp key. \n",
      "* The columns of Posizione Segnale was used to create another column using =IF(E2=\"\",\"NaN\",IF(E2=2,0,IF(E2=1,1,\"NaN\"))) as the cell value (replacing 2 with 0 for S2). \n",
      "* Also, Resp key was substituted with =IF(F2=\"\",\"NaN\",IF(F2=\"l\",0,IF(F2=\"a\",1,\"NaN\"))) cell value for 'a' and 'l' respones.\n",
      "* This data was was copied from Sheet 2 of the ..Research_Project\\Kinematics\\Action_observation\\Data\\Analysed_results\\final_results\\ folder\n",
      "* The data was saved in Sheet 3. IMP: The saved data is only in the local folder not in the server file.\n",
      "* This data was then copied and pasted into variable a in files Data_all_sub_meta_d_format_Laterale_18.mat and Data_all_sub_meta_d_format_Frontale.mat\n",
      "* (there was some problem with lateral data but this was rectified and data was aranged according to the subjects correctly).\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data analysis was performed using the meta_d_script.m which used a custom function meta_d_obs.m that selected the data according to time bin and then used trials2count.m supplied with the software to calculate counts and using a setting of padding (1) and 4 as number of ratings. Padding was done to avoid the cases where there were 0 counts. Even after the padding subject 7 in frontal view and subject 8 lateral view had problems with the optimisation algorithm (error : Objective function is undefined at initial point. Fmincon cannot continue. ). This was replaced with NaN values (8 in no. so that we can know which subject had this issue). \n",
      "\n",
      "fit values were saved as fit_all_subjects-8_frontale.mat and fit_all_subjects-Laterale_8.mat\n",
      "\n",
      "\n",
      "\n",
      "The other thing that can be done is to use SSE approach instead of fmin."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Results:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Results from the anova of meta-d' over time:\n",
      "Data taken from Final_results_meta_d'.xlsx\n",
      "\n",
      "Frontale:\n",
      "\n",
      "R:\n",
      "\n",
      "    meta_d_frontal <- read.table(file = \"clipboard\", sep = \"\\t\", header=FALSE)\n",
      "    View(meta_d_frontal)\n",
      "    library('reshape2')\n",
      "    meta_d_frontal_long_frmt <- melt(meta_d_frontal, id.vars = \"V1\")\n",
      "    meta_d_frontal_long_frmt$V1 <- factor(meta_d_frontal_long_frmt$V1)\n",
      "    meta_d_frontal_long_frmt$variable <- factor(meta_d_frontal_long_frmt$variable)\n",
      "    fit <- aov(value~variable+Error(V1/(variable)),data=meta_d_frontal_long_frmt)\n",
      "    summary(fit)\n",
      "\n",
      "\n",
      "results:\n",
      "Error: V1\n",
      "          Df Sum Sq Mean Sq F value Pr(>F)\n",
      "Residuals 17   91.4   5.376               \n",
      "\n",
      "Error: V1:variable\n",
      "           Df Sum Sq Mean Sq F value Pr(>F)    \n",
      "variable    7 208.73   29.82   36.35 <2e-16 ***\n",
      "Residuals 119  97.61    0.82                   \n",
      "---\n",
      "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\n",
      "\n",
      "\n",
      "\n",
      "JASP:\n",
      "\n",
      "Repeated Measures ANOVA \n",
      "\tSum of Squares \tdf \tMean Square \tF \tp \n",
      "Between Subjects \t\t\t\t\t\t\t\t\t\t\t\n",
      "     Residual \t\t91.40 \t\t17 \t\t5.376 \t\t\t\t\t\n",
      "Within Subjects \t\t\t\t\t\t\t\t\t\t\t\n",
      "     Time \t\t208.73 \t\t7 \t\t29.818 \t\t36.35 \t\t< .001 \t\n",
      "     Residual \t\t97.61 \t\t119 \t\t0.820 \t\t\t\t\t\n",
      "\n",
      "Note.  Type III Sum of Squares \n",
      "\n",
      "\n",
      "\n",
      "meta - d' Frontale vs Laterale: two way repeated Measures anova \n",
      "Data Sheet 3 of Final_results_meta_d'.xlsx\n",
      "\n",
      "R:\n",
      "    meta_d_frontal <- read.table(file = \"clipboard\", sep = \"\\t\", header=FALSE)\n",
      "    meta_d_frontal_long_frmt$V1 <- factor(meta_d_frontal_long_frmt$V1)\n",
      "    meta_d_frontal_long_frmt$variable <- factor(meta_d_frontal_long_frmt$variable)\n",
      "    meta_d_frontal_long_frmt$V10 <- factor(meta_d_frontal_long_frmt$V10)\n",
      "    fit <- aov(value~V10*variable+Error(V1/(V10*variable)),data=meta_d_frontal_long_frmt)\n",
      "    summary(fit)\n",
      "\n",
      "\n",
      "Error: V1\t\n",
      "          Df Sum Sq Mean Sq F value Pr(>F)\t\n",
      "Residuals 16  129.2   8.076               \t\n",
      "\t\n",
      "Error: V1:V10\t\n",
      "          Df Sum Sq Mean Sq F value Pr(>F)\t\n",
      "V10        1   0.00   0.000       0  0.999\t\n",
      "Residuals 16  33.54   2.096               \t\n",
      "\t\n",
      "Error: V1:variable\t\n",
      "           Df Sum Sq Mean Sq F value Pr(>F)    \t\n",
      "variable    7  393.5   56.22   54.33 <2e-16 ***\t\n",
      "\n",
      "Residuals 112  115.9    1.03                   \t\n",
      "---\t\n",
      "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\t\n",
      "\t\n",
      "Error: V1:V10:variable\t\n",
      "              Df Sum Sq Mean Sq F value Pr(>F)\t\n",
      "V10:variable   7   5.83  0.8323   1.232  0.291\t\n",
      "Residuals    112  75.66  0.6756 \t\n",
      "\n",
      "\n",
      "JASP:\n",
      "\n",
      "Data : Final_meta_d_jasp_frontale_laterale.csv\n",
      "\n",
      "Repeated Measures ANOVA\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\tSum of Squares\t\tdf\t\tMean Square\t\tF\t\tp\t\n",
      "Between Subjects\t\t\t\t\t\t\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t129.219\t\t16\t\t8.076\t\t\t\t\t\n",
      "Within Subjects\t\t\t\t\t\t\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Perspective\t\t2.708e\u2009\u22126\t\t1\t\t2.708e\u2009\u22126\t\t1.292e\u2009\u22126\t\t0.999\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t33.541\t\t16\t\t2.096\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Time\t\t393.525\t\t7\t\t56.218\t\t54.331\t\t<\u00a0.001\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t115.89\t\t112\t\t1.035\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Perspective:Time\t\t5.826\t\t7\t\t0.832\t\t1.232\t\t0.291\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t75.662\t\t112\t\t0.676\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\n",
      "Note. \u00a0Type III Sum of Squares\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Results from d' values:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There was some discrepency in teh results that I found and what there were in the paper. I need to check if my procedure is correct or not.\n",
      "\n",
      "There are differences in the actual F scores and the p values:\n",
      "\n",
      "\n",
      "what I get:\n",
      "\n",
      "\n",
      "Repeated Measures ANOVA\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\tSum of Squares\t\tdf\t\tMean Square\t\tF\t\tp\t\n",
      "Between Subjects\t\t\t\t\t\t\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t11.869\t\t18\t\t0.659\t\t\t\t\t\n",
      "Within Subjects\t\t\t\t\t\t\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Persp\t\t0.092\t\t1\t\t0.092\t\t0.155\t\t0.698\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t10.709\t\t18\t\t0.595\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Time\t\t468.027\t\t7\t\t66.861\t\t427.32\t\t<\u00a0.001\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t19.715\t\t126\t\t0.156\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Persp:Time\t\t7.061\t\t7\t\t1.009\t\t6.531\t\t<\u00a0.001\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t19.462\t\t126\t\t0.154\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\n",
      "Note. \u00a0Type III Sum of Squares\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "R:\n",
      "\n",
      "\n",
      "Error: V1\n",
      "          Df Sum Sq Mean Sq F value Pr(>F)\n",
      "Residuals 18  11.87  0.6594               \n",
      "\n",
      "Error: V1:V10\n",
      "          Df Sum Sq Mean Sq F value Pr(>F)\n",
      "V10        1  0.092  0.0924   0.155  0.698\n",
      "Residuals 18 10.709  0.5950               \n",
      "\n",
      "Error: V1:variable\n",
      "           Df Sum Sq Mean Sq F value Pr(>F)    \n",
      "variable    7  468.0   66.86   427.3 <2e-16 ***\n",
      "Residuals 126   19.7    0.16                   \n",
      "---\n",
      "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\n",
      "\n",
      "Error: V1:V10:variable\n",
      "              Df Sum Sq Mean Sq F value  Pr(>F)    \n",
      "V10:variable   7  7.061  1.0087   6.531 1.4e-06 ***\n",
      "Residuals    126 19.462  0.1545                    \n",
      "---\n",
      "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "##what was in the paper:\n",
      "Time : (F(7,126) = 376.053, p < .000; \u03b7\u00b2 = .954) and a significant interaction \u2018Time\u2019 by \u2018Viewpoint\u2019 (F(7, 126) = 4.972, p < .001; \u03b7\u00b2 = .216).\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Results from meta_d'/d'"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "R:\n",
      "results from ratio:\n",
      "\n",
      "\n",
      "Error: V1\t\n",
      "          Df Sum Sq Mean Sq F value Pr(>F)\t\n",
      "Residuals 16  61.69   3.856               \t\n",
      "\t\n",
      "Error: V1:V10\t\n",
      "          Df Sum Sq Mean Sq F value Pr(>F)  \t\n",
      "V10        1  30.95  30.946   3.447 0.0819 .\t\n",
      "Residuals 16 143.66   8.979                 \t\n",
      "---\t\n",
      "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\t\n",
      "\t\n",
      "Error: V1:variable\t\n",
      "           Df Sum Sq Mean Sq F value Pr(>F)\t\n",
      "variable    7   60.9   8.705   1.667  0.124\t\n",
      "Residuals 112  584.8   5.222               \t\n",
      "\t\n",
      "Error: V1:V10:variable\t\n",
      "              Df Sum Sq Mean Sq F value Pr(>F)\t\n",
      "V10:variable   7   44.9   6.416   1.426  0.202\t\n",
      "Residuals    112  504.0   4.500 \t\n",
      "\n",
      "\n",
      "Jasp:\n",
      "Repeated Measures ANOVA\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\tSum of Squares\t\tdf\t\tMean Square\t\tF\t\tp\t\n",
      "Between Subjects\t\t\t\t\t\t\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t61.69\t\t16\t\t3.856\t\t\t\t\t\n",
      "Within Subjects\t\t\t\t\t\t\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Persp\t\t30.95\t\t1\t\t30.946\t\t3.447\t\t0.082\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t143.66\t\t16\t\t8.979\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Time\t\t60.93\t\t7\t\t8.705\t\t1.667\t\t0.124\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t584.84\t\t112\t\t5.222\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Persp:Time\t\t44.92\t\t7\t\t6.416\t\t1.426\t\t0.202\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t503.98\t\t112\t\t4.5\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\n",
      "Note. \u00a0Type III Sum of Squares\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Results from difference:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Error: V1\t\n",
      "          Df Sum Sq Mean Sq F value Pr(>F)\t\n",
      "Residuals 16  88.27   5.517               \t\n",
      "\t\n",
      "Error: V1:V10\t\n",
      "          Df Sum Sq Mean Sq F value Pr(>F)\t\n",
      "V10        1  0.011  0.0113   0.007  0.937\t\n",
      "Residuals 16 27.600  1.7250               \t\n",
      "\t\n",
      "Error: V1:variable\t\n",
      "           Df Sum Sq Mean Sq F value Pr(>F)\t\n",
      "variable    7   5.72  0.8169   0.665  0.701\t\n",
      "Residuals 112 137.52  1.2279               \t\n",
      "\t\n",
      "Error: V1:V10:variable\t\n",
      "              Df Sum Sq Mean Sq F value Pr(>F)  \t\n",
      "V10:variable   7  13.81  1.9722   2.122 0.0468 *\t\n",
      "Residuals    112 104.10  0.9294                 \t\n",
      "---\t\n",
      "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\t\n",
      "\n",
      "\n",
      "Repeated Measures ANOVA\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\tSum of Squares\t\tdf\t\tMean Square\t\tF\t\tp\t\n",
      "Between Subjects\t\t\t\t\t\t\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t88.27\t\t16\t\t5.517\t\t\t\t\t\n",
      "Within Subjects\t\t\t\t\t\t\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Persp\t\t0.011\t\t1\t\t0.011\t\t0.007\t\t0.937\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t27.6\t\t16\t\t1.725\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Time\t\t5.719\t\t7\t\t0.817\t\t0.665\t\t0.701\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t137.524\t\t112\t\t1.228\t\t\t\t\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Persp:Time\t\t13.805\t\t7\t\t1.972\t\t2.122\t\t0.047\t\n",
      "\u00a0\u00a0\u00a0\u00a0\u00a0Residual\t\t104.096\t\t112\t\t0.929\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\n",
      "Note. \u00a0Type III Sum of Squares\t\t\t\t\t\t\t\t\t\t\t\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Result : Analysis with SSE"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The entire analysis mentioned above was performed MLE estimation. The alternated way is the SSE approach that the software providers have given. The difference as mentioned on their website (http://www.columbia.edu/~bsm2105/type2sdt/) is \n",
      "\n",
      "*\"One set uses maximum likelihood estimation (MLE), and the other works by minimizing the sum of squared errors (SSE). The functions using MLE estimation make use of Matlab's optimization toolbox. The functions that work with SSE don't require optimization toolbox, but use a cruder and slower model-fitting algorithm. \"*\n",
      "\n",
      "There is no correct method. The values however are different by some random value. The only advantage in SSE is that we dont have issues of missing result (Sub 8 from frontale and sub 9 from lateral). we can decide on which measure to use.\n",
      "\n",
      "The results are again in the Final_results_meta_d'.xlsx file\n",
      "\n",
      "Of course, all the results are in the meta_d_results.pptx file\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Misc comments"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For 10 times in the MLE analysis the following was printed : \n",
      "Local minimum possible. Constraints satisfied.\n",
      "\n",
      "Otherwise :\n",
      "Local minimum found that satisfies the constraints.\n",
      "\n",
      "Not sure of the significance of either."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "------------------------------------------------------------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Checking results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok there was an issue with the results not matching with the one shown in the results. I checked multiple things and following are the reasons that I think the results should be correct:\n",
      "* I checked with both R and JASP (which as you can see show exactly the same results)\n",
      "\n",
      "* The formula for repeated measures anova is correct for R - (Two factor design with repeated measures on both factors:\n",
      "DV ~ IV1 * IV2 + Error(subject/(IV1*IV2))). http://ww2.coastal.edu/kingw/statistics/R-tutorials/repeated.html\n",
      "\n",
      "* The formula in case of JASP is correct.\n",
      "\n",
      "* I calculated the value sum of squares for the factors by hand ( from formula of two way anova which is same for rm as well - http://statweb.stanford.edu/~susan/courses/s141/exanova.pdf) and i get same values. this is saved in file - rmanova_formula.xlsx\n",
      "\n",
      "* Since this was calculated from a diff formula, I checked with formula for repeated measures with one factor - https://statistics.laerd.com/statistical-guides/repeated-measures-anova-statistical-guide-2.php. This analysis was performed in R as well and I get the same values for both calculation by hand and R (fit <- aov(value~variable+Error(V1/(variable)),data=meta_d_frontal_long_frmt))\n",
      "\n",
      "* Finally, I used a simplified analysis from online source - http://vassarstats.net/anova202corr.html with 4 observations (for two subjects) and I get the same result. This result is in sheet 3. \n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Multiple Comparisons"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Multiple comparison tests were perfored with pain by lme from nlme package.\n",
      "\n",
      "\n",
      "require(nlme)         ## for lme()\n",
      "require(multcomp)  ## for multiple comparison stuff\n",
      "\n",
      "anova(fitlme <- lme(value~V10*variable, random=list(V1=pdBlocked(list(~1, pdCompSymm(~V10-1), pdCompSymm(~variable-1)))),  method=\"ML\", data=meta_d_frontal_long_frmt))\n",
      "\n",
      "\n",
      "anova(fitlme <- lme(value ~ V10*variable, random=list(V1=pdBlocked(list(~1, pdIdent(~V10-1), pdIdent(~variable-1)))),\n",
      "          method=\"ML\", data=meta_d_frontal_long_frmt))\n",
      "          \n",
      "posthoc <- glht(fitlme, linfct = mcp(variable = \"Tukey\"))\n",
      "summary(posthoc)\n",
      "\n",
      "\n",
      "help from http://www.uni-kiel.de/psychologie/rexrepos/posts/anovaMixed.html#two-way-repeated-measures-anova-rbf-pq-design and http://www.jason-french.com/tutorials/repeatedmeasures.html\n",
      "\n",
      "\n",
      "Issues with the result:\n",
      "\n",
      "\n",
      "Warning message:\n",
      "In mcp2matrix(model, linfct = linfct) :\n",
      "  covariate interactions found -- default contrast might be inappropriate\n",
      "  \n",
      "Suggested answer from :http://stats.stackexchange.com/questions/5250/multiple-comparisons-on-a-mixed-effects-model\n",
      "\n",
      "is that *Because it is impossible to determine the parameters of interest automatically in this case, mcp() in multcomp will by default generate comparisons for the main effects only, ignoring covariates and interactions. Since version 1.1-2, one can specify to average over interaction terms and covariates using arguments interaction_average = TRUE and covariate_average = TRUE respectively, whereas versions older than 1.0-0 automatically averaged over interaction terms. We suggest to the users, however, that they write out, manually, the set of contrasts they want. One should do this whenever there is doubt about what the default contrasts measure, which typically happens in models with higher order interaction terms. We refer to Hsu (1996), Chapter~7, and Searle (1971), Chapter~7.3, for further discussions and examples on this issue.*\n",
      "\n",
      "Apparantly from the pdf http://cran.r-project.org/web/packages/multcomp/vignettes/generalsiminf.pdf \n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Results from multiple comparison"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Results:\n",
      "\t Simultaneous Tests for General Linear Hypotheses\n",
      "\n",
      "Multiple Comparisons of Means: Tukey Contrasts\n",
      "\n",
      "\n",
      "Fit: lme.formula(fixed = value ~ V10 * variable, data = meta_d_frontal_long_frmt, \n",
      "    random = list(V1 = pdBlocked(list(~1, pdIdent(~V10 - 1), \n",
      "        pdIdent(~variable - 1)))), method = \"ML\")\n",
      "\n",
      "Linear Hypotheses:\n",
      "             Estimate Std. Error z value Pr(>|z|) "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = \"\"\"<table>\n",
      "<tr> <td>V3 - V2 == 0  0.33788    0.30771   1.098  0.95744 </td></tr>    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<tr><td>4 - V2 == 0  1.66904    0.30771   5.424  < 0.001 *** </tr>\n",
      "<tr><td>V5 - V2 == 0  1.99149    0.30771   6.472  < 0.001 ***</tr>\n",
      "<tr><td>V6 - V2 == 0  2.89057    0.30771   9.394  < 0.001 *** </tr>\n",
      "<tr><td>V7 - V2 == 0  3.13216    0.30771  10.179  < 0.001 ***\n",
      "<tr><td>V8 - V2 == 0  2.90103    0.30771   9.428  < 0.001 ***\n",
      "<tr><td>V9 - V2 == 0  3.29127    0.30771  10.696  < 0.001 ***\n",
      "<tr><td>V4 - V3 == 0  1.33116    0.30771   4.326  < 0.001 ***\n",
      "<tr><td>V5 - V3 == 0  1.65360    0.30771   5.374  < 0.001 ***\n",
      "<tr><td>V6 - V3 == 0  2.55269    0.30771   8.296  < 0.001 ***\n",
      "<tr><td>V7 - V3 == 0  2.79427    0.30771   9.081  < 0.001 ***\n",
      "<tr><td>V8 - V3 == 0  2.56314    0.30771   8.330  < 0.001 ***\n",
      "<tr><td>V9 - V3 == 0  2.95339    0.30771   9.598  < 0.001 ***\n",
      "<tr><td>V5 - V4 == 0  0.32244    0.30771   1.048  0.96702    \n",
      "<tr><td>V6 - V4 == 0  1.22153    0.30771   3.970  0.00180 ** \n",
      "<tr><td>V7 - V4 == 0  1.46311    0.30771   4.755  < 0.001 ***\n",
      "<tr><td>V8 - V4 == 0  1.23198    0.30771   4.004  0.00166 ** \n",
      "<tr><td>V9 - V4 == 0  1.62223    0.30771   5.272  < 0.001 ***\n",
      "<tr><td>V6 - V5 == 0  0.89908    0.30771   2.922  0.06844 .  \n",
      "<tr><td>V7 - V5 == 0  1.14067    0.30771   3.707  0.00509 ** \n",
      "<tr><td>V8 - V5 == 0  0.90954    0.30771   2.956  0.06170 .  \n",
      "<tr><td>V9 - V5 == 0  1.29979    0.30771   4.224  < 0.001 ***\n",
      "<tr><td>V7 - V6 == 0  0.24159    0.30771   0.785  0.99391    \n",
      "<tr><td>V8 - V6 == 0  0.01046    0.30771   0.034  1.00000    \n",
      "<tr><td>V9 - V6 == 0  0.40070    0.30771   1.302  0.89835    \n",
      "<tr><td>V8 - V7 == 0 -0.23113    0.30771  -0.751  0.99536    \n",
      "<tr><td>V9 - V7 == 0  0.15912    0.30771   0.517  0.99958    \n",
      "<tr><td>V9 - V8 == 0  0.39025    0.30771   1.268  0.91069</tr>  \n",
      "\n",
      "<tr><td>Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\n",
      "(Adjusted p values reported -- single-step method) </td></tr>\n",
      "</table>\"\"\"\n",
      "h = HTML(s); h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table>\n",
        "<tr> <td>V3 - V2 == 0  0.33788    0.30771   1.098  0.95744 </td></tr>    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<tr><td>4 - V2 == 0  1.66904    0.30771   5.424  < 0.001 *** </tr>\n",
        "<tr><td>V5 - V2 == 0  1.99149    0.30771   6.472  < 0.001 ***</tr>\n",
        "<tr><td>V6 - V2 == 0  2.89057    0.30771   9.394  < 0.001 *** </tr>\n",
        "<tr><td>V7 - V2 == 0  3.13216    0.30771  10.179  < 0.001 ***\n",
        "<tr><td>V8 - V2 == 0  2.90103    0.30771   9.428  < 0.001 ***\n",
        "<tr><td>V9 - V2 == 0  3.29127    0.30771  10.696  < 0.001 ***\n",
        "<tr><td>V4 - V3 == 0  1.33116    0.30771   4.326  < 0.001 ***\n",
        "<tr><td>V5 - V3 == 0  1.65360    0.30771   5.374  < 0.001 ***\n",
        "<tr><td>V6 - V3 == 0  2.55269    0.30771   8.296  < 0.001 ***\n",
        "<tr><td>V7 - V3 == 0  2.79427    0.30771   9.081  < 0.001 ***\n",
        "<tr><td>V8 - V3 == 0  2.56314    0.30771   8.330  < 0.001 ***\n",
        "<tr><td>V9 - V3 == 0  2.95339    0.30771   9.598  < 0.001 ***\n",
        "<tr><td>V5 - V4 == 0  0.32244    0.30771   1.048  0.96702    \n",
        "<tr><td>V6 - V4 == 0  1.22153    0.30771   3.970  0.00180 ** \n",
        "<tr><td>V7 - V4 == 0  1.46311    0.30771   4.755  < 0.001 ***\n",
        "<tr><td>V8 - V4 == 0  1.23198    0.30771   4.004  0.00166 ** \n",
        "<tr><td>V9 - V4 == 0  1.62223    0.30771   5.272  < 0.001 ***\n",
        "<tr><td>V6 - V5 == 0  0.89908    0.30771   2.922  0.06844 .  \n",
        "<tr><td>V7 - V5 == 0  1.14067    0.30771   3.707  0.00509 ** \n",
        "<tr><td>V8 - V5 == 0  0.90954    0.30771   2.956  0.06170 .  \n",
        "<tr><td>V9 - V5 == 0  1.29979    0.30771   4.224  < 0.001 ***\n",
        "<tr><td>V7 - V6 == 0  0.24159    0.30771   0.785  0.99391    \n",
        "<tr><td>V8 - V6 == 0  0.01046    0.30771   0.034  1.00000    \n",
        "<tr><td>V9 - V6 == 0  0.40070    0.30771   1.302  0.89835    \n",
        "<tr><td>V8 - V7 == 0 -0.23113    0.30771  -0.751  0.99536    \n",
        "<tr><td>V9 - V7 == 0  0.15912    0.30771   0.517  0.99958    \n",
        "<tr><td>V9 - V8 == 0  0.39025    0.30771   1.268  0.91069</tr>  \n",
        "\n",
        "<tr><td>Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\n",
        "(Adjusted p values reported -- single-step method) </td></tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "<IPython.core.display.HTML at 0x49da6d8>"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "References"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* http://statweb.stanford.edu/~susan/courses/s141/exanova.pdf\n",
      "* https://statistics.laerd.com/statistical-guides/repeated-measures-anova-statistical-guide-2.php\n",
      "* http://www.columbia.edu/~bsm2105/type2sdt/\n",
      "* http://www.psych.upenn.edu/~baron/rpsych/rpsych.html#htoc60\n",
      "* http://www.psych.upenn.edu/~baron/rpsych/rpsych.html\n",
      "* http://yatani.jp/teaching/doku.php?id=hcistats:posthoc\n",
      "\n",
      "* For multiple comparisons : http://www.jason-french.com/tutorials/repeatedmeasures.html\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}